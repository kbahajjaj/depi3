{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3d3cc01-4ab1-49fb-baf4-b2820b9c0ae0",
   "metadata": {},
   "source": [
    "# Web scraping Task\n",
    "##### Student: Khalid Salim\n",
    "##### Student Number: 2\n",
    "##### Group: CAI3_AIS4_G1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33517d0b-2669-4a87-b249-90a3457956d2",
   "metadata": {},
   "source": [
    "## For the webpage: https://baraasalout.github.io/test.html, perform the following tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb60c15-4ff9-4231-97d7-2ca80154772b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Importing required libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fdfa99-98f2-4394-b7e0-98a59d97fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing required libraries\n",
    "#!pip install requests\n",
    "#!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a7e1a9-1622-4afb-b1ad-a7f520c973e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required modules and functions\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "import gc\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ab92ef-b1cd-4785-b844-037d54aca31d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Task 1 - Extract Text Data:\n",
    "* Extract all headings (`<h1>`, `<h2>`).\n",
    "* Extract all text content inside `<p>` and `<li>` tags.\n",
    "* Save this data into a `Extract_Text_Data.CSV` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc9a5a7-93f1-4ebc-b818-849cb13d08c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting page HTML code\n",
    "url = 'https://baraasalout.github.io/test.html'\n",
    "\n",
    "page = requests.get(url)\n",
    "#print(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb14a850-4aab-4198-8c63-557ab3cecc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing HTML content\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e48443-a4fe-41d5-923b-54cc4f3d9f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b595d7f8-d74e-4f56-8218-24a7ec05b725",
   "metadata": {},
   "source": [
    "#### Extract all headings (`<h1>`, `<h2>`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369cbf86-be52-46a9-892f-89acddf2d6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_headings = soup.find_all('h1')\n",
    "h1_headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7fa964-b766-46a5-aae4-d8b209bed4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(h1_headings[0].get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5876b9-d9f9-434f-b677-5c5236eed3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_headings = soup.find_all('h2')\n",
    "h2_headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8786436b-49a2-48ff-aa8e-2b1c9ad47538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for heading in h2_headings:\n",
    "#    print(heading.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61adddde-0a68-43ee-983a-cf0ae5fb46e7",
   "metadata": {},
   "source": [
    "#### Extract all text content inside `<p>` and `<li>` tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12dd7a0-6007-4914-8197-831a3949e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = soup.find_all('p')\n",
    "paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bf6ed4-02e1-4d5d-83d5-9a29d6b0ff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = soup.find_all('li')\n",
    "listings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bba8f05-d315-4508-a56c-7470aa3141e3",
   "metadata": {},
   "source": [
    "#### Save this data into a `Extract_Text_Data.CSV` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f936e265-836a-4daf-91e2-7413e81cad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arranging data\n",
    "header = [['Type', 'Content']] # csv file header\n",
    "h1_headings_data = [['Heading', row.get_text()] for row in h1_headings]\n",
    "#print(*h1_headings_data, sep='\\n')\n",
    "h2_headings_data = [['Heading', row.get_text()] for row in h2_headings]\n",
    "paragraph_data = [['Paragraph', row.get_text()] for row in paragraphs]\n",
    "#print(*paragraph_data, sep='\\n')\n",
    "listing_data = [['Listing', row.get_text()] for row in listings]\n",
    "#print(*listing_data, sep='\\n')\n",
    "\n",
    "# data to be saved into csv\n",
    "extracted_data = header\n",
    "extracted_data.extend(h1_headings_data)\n",
    "extracted_data.extend(h2_headings_data)\n",
    "extracted_data.extend(paragraph_data)\n",
    "extracted_data.extend(listing_data)\n",
    "#print(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab50d2-8f14-47a8-8fc1-32f7bb648034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating csv file to save data into\n",
    "with open('task1_extract_text_data.csv', 'w', encoding='utf-8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbcc41c-28e7-489e-97a6-94759ff51bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing memory for task 1\n",
    "del page\n",
    "del h1_headings\n",
    "del h2_headings\n",
    "del paragraphs\n",
    "del extracted_data\n",
    "del paragraph_data\n",
    "del listings\n",
    "del listing_data\n",
    "del header\n",
    "del h1_headings_data\n",
    "del h2_headings_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143cb8c9-1572-40b3-bf14-b014808d5eda",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Task 2 - Extract Table Data:\r",
    "\r\n",
    "- Product Name.\r\n",
    "- Price.\r\n",
    "- Stock Status.us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132eed33-db0a-4403-8a62-dc9f07b2fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing table data for csv file\n",
    "tables = soup.find('table')\n",
    "tables = tables.get_text().split('\\n\\n\\n')\n",
    "tables_data = [row.split('\\n') for row in tables]\n",
    "extracted_data = [[item for item in row if item != \"\"] for row in tables_data]\n",
    "print(tables)\n",
    "print(tables_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f862fa80-f350-49c6-a609-422f53118cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating csv file for table data\n",
    "with open('task2_extract_table_data.csv', 'w', encoding='utf-8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f229b-4648-448b-9e29-e6c40b7c0fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing memory for task 2\n",
    "del tables\n",
    "del tables_data\n",
    "del extracted_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce44f705-bf7b-4e65-aef2-33f5932eafbe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Task 3 - Extract Product Information (Card Section):\n",
    "- Extract data from the book cards at the bottom of the page, including:\r",
    "    \n",
    "- Book Title.    \r\n",
    "- Price    .\r\n",
    "- Stock Availabil  y.\r\n",
    "- Button text (e.g., \"Add to basket\"). \r\n",
    "- Save the dataproductiict_Informa` JSON fileary-\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f2a07a-c2af-4ff9-9a6b-501d6d5aa366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting card section\n",
    "cards = soup.find('div')\n",
    "cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b75d2a5-d194-4a4b-ade8-a31ab874e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting card tags\n",
    "cards_title = cards.find_all('p')\n",
    "cards_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18882b43-0536-4a43-ad10-43727feff82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting card information from tags\n",
    "card_info = [title.get_text().split('\\n') for title in cards]\n",
    "card_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a599196-6597-41b3-a3e9-8e2007079d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing empty lists from card information\n",
    "card_info = [[info for info in book if info !=\"\"] for book in card_info]\n",
    "card_info = [row for row in card_info if row]\n",
    "card_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0ec58c-7903-46bb-8dc9-e79c00f3c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data for json file\n",
    "dict_keys = ['item'+str(i) for i in range(1, len((card_info))+1)]\n",
    "cards_data = {dict_keys[i] : card_info[i] for i in range(len(dict_keys))}\n",
    "cards_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aba7dc-8583-473d-9f53-b3218cc38c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('task3_product_information.json', 'w') as json_file:\n",
    "    json.dump(cards_data, json_file)\n",
    "print(json.dumps(cards_data, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c8c75-585a-46e9-99ee-bffcb2ca670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing memory for task 3\n",
    "del cards\n",
    "del cards_title\n",
    "del card_info\n",
    "del dict_keys\n",
    "del cards_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad8d135-9aa0-4367-a6df-d74bb6b7818d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Task 4 - Extract From Details:\n",
    "Extract all input fields from the form, including:\n",
    "- Field name (e.g., username, password).\n",
    "- Input type (e.g., text, password, checkbox, etc.).\n",
    "- Default values, if any.\n",
    "- Save the data into a `JSON` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fb75a8-2508-4a8b-949a-424f9e66b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "form_tag = soup.find('form')\n",
    "form_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b38e81-e0cc-47e7-a6fa-5dd128402e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Field Names:\n",
    "name_tags = form_tag.find_all('label')\n",
    "#print(name_tags)\n",
    "name_tags = name_tags[:-1]\n",
    "field_names = [name_tag.get_text().replace(\":\", \"\") for name_tag in name_tags if \":\" in name_tag.get_text()]\n",
    "#field_names = [name.replace(\":\", \"\") for name in field_names if \":\" in name]\n",
    "# adding options name\n",
    "#field_names = field_names.append(options_tag.attrs['name'])\n",
    "#field_names.append(options_tag)\n",
    "print(field_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b7293d-37df-4d72-8434-fc7855317165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Input Types:\n",
    "input_tags = form_tag.find_all('input')\n",
    "input_types = [input_tag['type'] for input_tag in input_tags if 'type' in input_tag.attrs]\n",
    "input_types = input_types[:-1]\n",
    "print(input_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38519401-1ecb-4e12-8aa8-a526fa613d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting default values\n",
    "input_tags = form_tag.find_all('input')[:-2]\n",
    "names_def_val = [tag.attrs['value'] if 'value' in tag.attrs else \"\" for tag in input_tags] # only for name, password\n",
    "options_def_val = form_tag.find('option').attrs['value']\n",
    "names_def_val.append(options_def_val)\n",
    "name_tags\n",
    "input_tags\n",
    "print(names_def_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d892d3-cc73-4e43-b9cc-3c65572f3703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data in dictionary of dictionaries format for json file\n",
    "\n",
    "# The dictionary of dictionaries keys\n",
    "dict_keys = ['field_'+str(i+1) for i in range(len(field_names))]\n",
    "#print(dict_keys)\n",
    "\n",
    "# Inner dictionaries keys \n",
    "sub_dict_keys = ['Name', 'Input Type', 'Default Value'] \n",
    "\n",
    "# Inner dictionary values: list of tuples from elements of field_names, input_types and default value \n",
    "sub_dict_vals = list(zip(field_names, input_types, names_def_val)) \n",
    "print(list(zip(sub_dict_keys, list(sub_dict_vals)[1])))\n",
    "\n",
    "# Creating the large dictionaries from inner dictionries\n",
    "data_dict = {}\n",
    "for i in range(len(field_names)):\n",
    "    data_dict[dict_keys[i]] = {k:v for k,v in zip(sub_dict_keys, sub_dict_vals[i])} \n",
    "    \n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061b8c6f-1117-42b9-be89-05c0aa552a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumping the data into the json file\n",
    "with open('task4_field_details_info.json', 'w') as file:\n",
    "    json.dump(data_dict, file)\n",
    "print(json.dumps(data_dict, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a2b552-69f6-484f-9cbc-3ac98a4cdbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing memory for task 4\n",
    "del form_tag\n",
    "del field_names\n",
    "del input_types\n",
    "del names_def_val\n",
    "del dict_keys\n",
    "del sub_dict_keys\n",
    "del data_dict\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67bdfae-e6c9-4b52-b72b-d22bb6b49773",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Task 5 - Extract Links and Multimedia: \n",
    "- Extract the video link from the `<iframe>` tag.\n",
    "- Save the data into a .JSON filery-\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad00d8bb-a7c5-4263-a583-adfaf8634173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting media link and dumping it into the json file\n",
    "media_tag = soup.find('iframe')\n",
    "media_link = media_tag.attrs['src']\n",
    "#print(media_link)\n",
    "link_dict = {'link' : media_link}\n",
    "with open('task5_media_links.json', 'w') as f:\n",
    "    json.dump(link_dict, f)\n",
    "print(json.dumps(link_dict, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974072d4-6e25-40ae-a71d-6ef24cc41bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumping the data into the json file\n",
    "media_tag = soup.find_all('iframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef3e90a-f56e-41b0-bd72-7801dd6a32e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing memory for task 5\n",
    "del media_tag\n",
    "del media_link\n",
    "del link_dict\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14242261-6a12-48c8-bf54-f9284a6e8dac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Task 6 - Scraping Challenge: \n",
    "Students must write a script to extract data from the Featured Products section with the following requirements:\n",
    "- Product Name: Located within `<span class=\"name\">`.\n",
    "- Hidden Price: Located within `<span class=\"price\">`, which has `style=\"display: none;\"`.\n",
    "- Available Colors: Located within `<span class=\"colors\">`.\n",
    "- Product ID: The value stored in the data-id attribute.\n",
    "- Example Output:\n",
    "  \n",
    "  `[`<br />\n",
    "  ` {'id': '101', 'name': 'Wireless Headphones', 'price': '$49.99', 'colors': 'Black, White, Blue'},`<br />\n",
    "  ` {'id': '102', 'name': 'Smart Speaker', 'price': '$89.99', 'colors': 'Grey, Black'},`<br />\n",
    "  ` {'id': '103', 'name': 'Smart Watch', 'price': '$149.99', 'colors': 'Black, Silver, Gold'}`<br />\n",
    "  `]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45a5392-0027-4639-af9f-a3cc045b89dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting featured products tags\n",
    "feat_prod_tags = soup.find_all('div', class_='products')\n",
    "feat_prod_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c78a37-e876-4907-82bd-4d7014779079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting featured products field values (i.e id, name, price, colors)\n",
    "ids_list = [tag.attrs['data-id'] for tag in feat_prod_tags[0].find_all('div', class_='product-card')]\n",
    "names_list = [tag.get_text() for tag in feat_prod_tags[0].find_all('p', class_='name')]\n",
    "price_list = [tag.get_text() for tag in feat_prod_tags[0].find_all('p', class_='price')]\n",
    "colors_list = [tag.get_text().replace(\"Available colors: \", \"\") \\\n",
    "               for tag in feat_prod_tags[0].find_all('p', class_='colors')]\n",
    "# print(ids_list)\n",
    "# print(names_list)\n",
    "# print(price_list)\n",
    "# print(colors_list)\n",
    "\n",
    "dict_keys = ['id', 'name', 'price', 'colors'] \n",
    "dict_vals = list(zip(ids_list, names_list, price_list, colors_list))\n",
    "# print(dict_keys)\n",
    "# print(dict_vals)\n",
    "# print(list(zip(dict_keys, dict_vals[2])))\n",
    "\n",
    "# constructing featured products data list of dictionaries\n",
    "feat_prod_data = []\n",
    "for i in range(len(ids_list)):\n",
    "    feat_prod_data.append(dict(zip(dict_keys, dict_vals[i])))\n",
    "    # or another alternative:\n",
    "    # feat_prod_data.append({k:v for k,v in zip(dict_keys, dict_vals[i])})\n",
    "\n",
    "feat_prod_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6dc061-f30b-4bad-9b83-8a2247a342a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4437b2-ce80-4e29-9f98-e1a56dab26f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depi3",
   "language": "python",
   "name": "depi3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
